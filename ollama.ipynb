{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama with LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet --upgrade langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from opik.integrations.langchain import OpikTracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Existing Opik clients will not use updated values for \"url\", \"api_key\", \"workspace\".\n",
      "OPIK: Opik is already configured. You can check the settings by viewing the config file at C:\\Users\\DELL\\.opik.config\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "opik.configure(use_local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Opik tracer\n",
    "opik_tracer = OpikTracer(tags=[\"langchain\", \"ollama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Ollama model and configure it to use the Opik tracer\n",
    "llm = ChatOllama(\n",
    "    model=\"minicpm-v\",\n",
    "    temperature=0.7,\n",
    ").with_config({\"callbacks\": [opik_tracer]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's understandable if you're not interested in learning how to program, but it is an essential skill in today's job market. Many industries rely on computer technology, from healthcare to finance, so having a foundational understanding of coding can open up many career opportunities.\\nIf programming isn't something that interests or excites you, there are still ways for you to achieve success and grow your skills without learning how to code. Here are some suggestions:\\n1. Identify what motivates you: Are there other areas in technology that interest you? For example, do you enjoy writing or designing user interfaces? Perhaps marketing would be a better fit than programming.\\n2. Explore different fields within tech industry: Within the broader field of technology, consider exploring various industries and job roles to see which ones align with your interests and passions outside of coding.\\n3. Build transferable skills: Even if you're not interested in learning how to code specifically, there are many other technical skills that can be applied across different fields within tech industry such as project management or data analysis.\\n4. Consider pursuing an education related to a non-technical field instead of computer science/IT-related courses which often require knowledge on programming languages & algorithms.\\nRemember it's important not to force yourself into something you're not passionate about for the sake of career growth, but rather find what interests and motivates you while leveraging your strengths.\", additional_kwargs={}, response_metadata={'model': 'minicpm-v', 'created_at': '2025-03-19T10:24:41.1151172Z', 'done': True, 'done_reason': 'stop', 'total_duration': 169403931200, 'load_duration': 95773100, 'prompt_eval_count': 44, 'prompt_eval_duration': 29012000000, 'eval_count': 277, 'eval_duration': 140137000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-847b9037-dbfc-4db3-b5ba-c99c404e773a-0', usage_metadata={'input_tokens': 44, 'output_tokens': 277, 'total_tokens': 321})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Failed to process CreateSpansBatchMessage. Error: status_code: 401, body: {'code': 401, 'message': 'API key should be provided'}\n",
      "OPIK: Failed to process CreateTraceBatchMessage. Error: status_code: 401, body: {'code': 401, 'message': 'API key should be provided'}\n"
     ]
    }
   ],
   "source": [
    "# Call the Ollama model\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that can guide me as the teacher and parents too..\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"I hate programming and i want to switch for carrer grwoth.\",\n",
    "    ),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='(Adjusts microphone, leans in with a slightly mischievous grin)\\n\\nOkay, okay, let’s talk about overfitting. It’s like when you memorize the answers to a test instead of actually *understanding* the material. You ace that specific test, but you completely bomb when the questions are worded differently.  It\\'s a serious problem, especially when you\\'re building something – a model, a strategy, a life – and you want it to actually *work* in the real world.\\n\\nSo, how do we avoid this test-memorization trap? Let’s break it down, and I\\'ll throw in a few jokes to keep things interesting.\\n\\n**1. Data, Data, Data! (And a Little Bit of Variety)**\\n\\n* **More Data:** Honestly, this is the biggest one. The more data you have, the harder it is for your model to memorize specific quirks. Think of it like this: a really detailed dataset is like showing your model a *huge* range of scenarios.\\n* **Data Augmentation:**  This is where you get creative!  If you have limited data, you can artificially create more data by slightly altering existing data.  Like rotating a picture of a cat 10 degrees.  It\\'s like saying, \"Hey model, you’ve seen this cat from every angle!\" (Pause for laughter)\\n\\n**2. Simplify, Simplify, Simplify! (Don’t Overcomplicate Things)**\\n\\n* **Reduce Model Complexity:**  A really complex model (lots of layers in a neural network, a huge decision tree) is *perfect* at memorizing details. But it\\'s terrible at generalizing.  Try a simpler model first.  It\\'s like saying, \"Let’s not build a skyscraper when a sturdy shed will do!\"\\n* **Feature Selection:**  Are you using *every* single piece of data you have?  Some features might be noise, just random details that don\\'t actually contribute to the core understanding.  It’s like focusing on the irrelevant doodles in a textbook.\\n\\n**3. Regularization - The \"Don\\'t Be a Perfectionist\" Technique**\\n\\n* **L1 and L2 Regularization:** These add a penalty to the model\\'s complexity. It’s like saying, \"Hey model, you can be accurate, but don\\'t get *too* obsessed with every single tiny detail.\"\\n* **Dropout:** (Especially in neural networks) This randomly turns off some neurons during training. It forces the model to learn more robust features that aren’t reliant on specific connections.  It’s like saying, \"Okay, let’s see if you can still solve the problem if you lose a few of your best friends!\" (Winks)\\n\\n\\n**4. Cross-Validation - Test, Test, Test!**\\n\\n* **K-Fold Cross-Validation:** This is how you really know if your model is generalizing well. You split your data into multiple folds and train and test on different combinations.  It’s like running multiple tests on the same material to see if the results are consistent.\\n\\n\\n**Important Note:** There\\'s no magic bullet. Reducing overfitting is often a process of experimentation. You\\'ll try different techniques, monitor your results, and adjust your approach. \\n\\n**(Looks directly at the audience)**\\n\\nUltimately, the goal isn’t to create a model that perfectly memorizes the training data. It’s to build something that can *learn* and *adapt* to new situations. \\n\\n---\\n\\n**Now, let me ask you – what’s *your* biggest fear when it comes to building something new?  Don’t be afraid to share!** (Pauses for audience response) \\n\\nWould you like me to delve deeper into a specific technique, like dropout, or maybe give you a real-world example?', additional_kwargs={}, response_metadata={'model': 'Gemma3', 'created_at': '2025-03-23T04:34:23.1073195Z', 'done': True, 'done_reason': 'stop', 'total_duration': 206721325600, 'load_duration': 137424300, 'prompt_eval_count': 33, 'prompt_eval_duration': 10285001500, 'eval_count': 804, 'eval_duration': 196292142000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-7804184a-5ae8-4a62-bb43-d7d6e46e3165-0', usage_metadata={'input_tokens': 33, 'output_tokens': 804, 'total_tokens': 837})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from opik.integrations.langchain import OpikTracer\n",
    "\n",
    "# Create the Opik tracer\n",
    "opik_tracer = OpikTracer(tags=[\"langchain\", \"ollama\"])\n",
    "\n",
    "# Create the Ollama model and configure it to use the Opik tracer\n",
    "llm = ChatOllama(\n",
    "    model=\"Gemma3\",\n",
    "    temperature=0.7,\n",
    ").with_config({\"callbacks\": [opik_tracer]})\n",
    "\n",
    "# Call the Ollama model\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant for the motivation speaker and good comedian.\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"How can we reduce overfitting.\",\n",
    "    ),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Opik Proxy Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opik in d:\\vs code\\llmops\\venv\\lib\\site-packages (1.6.6)\n",
      "Collecting opik\n",
      "  Downloading opik-1.6.8-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: boto3-stubs>=1.34.110 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.15)\n",
      "Requirement already satisfied: click in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (8.1.8)\n",
      "Requirement already satisfied: httpx in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (0.28.1)\n",
      "Requirement already satisfied: levenshtein<1.0.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (0.27.1)\n",
      "Requirement already satisfied: litellm in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (1.63.11)\n",
      "Requirement already satisfied: openai<2.0.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (1.66.5)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (2.8.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (2.10.6)\n",
      "Requirement already satisfied: pytest in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (8.3.5)\n",
      "Requirement already satisfied: rich in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (13.9.4)\n",
      "Requirement already satisfied: sentry_sdk>=2.0.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (2.23.1)\n",
      "Requirement already satisfied: tenacity in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (9.0.0)\n",
      "Requirement already satisfied: tqdm in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (4.67.1)\n",
      "Requirement already satisfied: uuid6 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from opik) (2024.7.10)\n",
      "Requirement already satisfied: botocore-stubs in d:\\vs code\\llmops\\venv\\lib\\site-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.15)\n",
      "Requirement already satisfied: types-s3transfer in d:\\vs code\\llmops\\venv\\lib\\site-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.11.4)\n",
      "Requirement already satisfied: mypy-boto3-bedrock-runtime<1.38.0,>=1.37.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.7)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from levenshtein<1.0.0->opik) (3.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from openai<2.0.0->opik) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from openai<2.0.0->opik) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from openai<2.0.0->opik) (0.9.0)\n",
      "Requirement already satisfied: sniffio in d:\\vs code\\llmops\\venv\\lib\\site-packages (from openai<2.0.0->opik) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from openai<2.0.0->opik) (4.12.2)\n",
      "Requirement already satisfied: certifi in d:\\vs code\\llmops\\venv\\lib\\site-packages (from httpx->opik) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\vs code\\llmops\\venv\\lib\\site-packages (from httpx->opik) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\vs code\\llmops\\venv\\lib\\site-packages (from httpx->opik) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from httpcore==1.*->httpx->opik) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->opik) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->opik) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.0.0->opik) (1.0.1)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from sentry_sdk>=2.0.0->opik) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\vs code\\llmops\\venv\\lib\\site-packages (from tqdm->opik) (0.4.6)\n",
      "Requirement already satisfied: aiohttp in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (3.11.14)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (4.23.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in d:\\vs code\\llmops\\venv\\lib\\site-packages (from litellm->opik) (0.21.1)\n",
      "Requirement already satisfied: iniconfig in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pytest->opik) (2.0.0)\n",
      "Requirement already satisfied: packaging in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pytest->opik) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from pytest->opik) (1.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from rich->opik) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from rich->opik) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm->opik) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm->opik) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.23.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->opik) (0.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from tiktoken>=0.7.0->litellm->opik) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from tiktoken>=0.7.0->litellm->opik) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from aiohttp->litellm->opik) (1.18.3)\n",
      "Requirement already satisfied: types-awscrt in d:\\vs code\\llmops\\venv\\lib\\site-packages (from botocore-stubs->boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from tokenizers->litellm->opik) (0.29.3)\n",
      "Requirement already satisfied: filelock in d:\\vs code\\llmops\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\vs code\\llmops\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm->opik) (3.4.1)\n",
      "Downloading opik-1.6.8-py3-none-any.whl (418 kB)\n",
      "Installing collected packages: opik\n",
      "  Attempting uninstall: opik\n",
      "    Found existing installation: opik 1.6.6\n",
      "    Uninstalling opik-1.6.6:\n",
      "      Successfully uninstalled opik-1.6.6\n",
      "Successfully installed opik-1.6.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the latest version of the SDK\n",
    "! pip install opik -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! opik proxy --ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
